---
title: "01-1-Understanding Deep Learning (Introduction)"

categories:
  - DeepLearning
tags:
  - [Python, DeepLearning]

toc: true
toc_sticky: true

date: 2024-09-01
last_modified_at: 2024-09-01
---
> Hㅏ.... 책이 좋은데 TMI가 좀 많아서 좀 요약하면서 해보겠습니다. 
# 제1장 Introduction

## 소개

- 이 책은 인공지능(AI)과 머신 러닝, 특히 딥러닝의 기본 원리를 설명합니다.
- 머신 러닝은 AI의 하위 집합으로, 데이터에 기반하여 결정을 내리는 방법을 학습합니다.
- 딥러닝은 딥 뉴럴 네트워크를 활용한 머신 러닝 모델로, 다양한 실생활 응용 프로그램에서 사용됩니다.
- 이 책은 이론적이기보다는 아이디어를 설명하며, 실용적인 코드보다는 개념 이해에 중점을 둡니다.
- 마지막으로, 딥러닝의 윤리적 영향과 AI의 미래에 대해 간단히 논의합니다.

<img src="{{ site.url }}{{ site.baseurl }}/assets/img/understanding_dl/1-1.png" alt="">



## 1.1 Supervised learning
### 1.1.1 Regression and classification problems

이 그림(1.2)은 여러 회귀 및 분류 문제를 설명하는데 내용이 너무 많다;;

**간단하게 요약하면** 

문장, 음성 파일, 이미지 등을 숫자 벡터로 인코딩 &rarr; 블랙박스 &rarr; 벡터 출력 &rarr; 사람이 읽을수 있는 형식으로 다시 디코딩
이다!!

<img src="{{ site.url }}{{ site.baseurl }}/assets/img/understanding_dl/1-2.png" alt="">


- **그림 1.2a의 모델:** 주택의 크기와 침실 수와 같은 입력 특성에 기반해 주택의 가격을 예측합니다. 이는 연속적인 숫자를 반환하므로 회귀 문제입니다.
- **그림 1.2b의 모델:** 분자의 화학 구조를 입력으로 받아 동결점과 비등점을 예측합니다. 이는 여러 숫자를 예측하므로 다변량 회귀 문제입니다.
- **그림 1.2c의 모델:** 레스토랑 리뷰를 입력받아 긍정적인지 부정적인지를 예측합니다. 이는 이진 분류 문제로, 모델이 입력을 두 개의 범주 중 하나로 할당하려고 시도하기 때문입니다.
- **그림 1.2d와 1.2e의 모델:** 다중 클래스 분류 문제를 나타내며, 첫 번째 경우는 오디오 파일을 입력으로 받아 음악 장르를 예측하고, 두 번째 경우는 이미지를 입력으로 받아 물체의 종류를 예측합니다. 각 경우에서, 모델은 N개의 범주에 대한 확률을 포함하는 크기 N의 벡터를 반환합니다.


### 1.1.2 Inputs 
그림 1.2에서 입력 데이터는 다양하게 나타납니다

- **주택 가격 예측 예시**
    
    고정된 길이의 벡터. 이는 순서가 중요하지 않은 표 형식 데이터(tabular data), 입력 순서를 변경해도 모델 예측이 동일하게 유지
- **레스토랑 리뷰 예시**

  가변 길이의 텍스트로, 입력 순서가 중요 예를 들어 “내 아내가 치킨을 먹었다”와 “치킨이 내 아내를 먹었다”는 전혀 다른 의미 이 텍스트는 모델에 전달되기 전에 숫자 형식으로 인코딩됩니다. 
- **음악 분류 예시**

  고정된 크기의 입력 벡터(10초 클립)가 매우 고차원적일 수 있습니다. 디지털 오디오는 441,000개의 정수로 구성됩니다. 따라서 지도 학습 모델은 큰 입력을 처리할 수 있어야 합니다.
- **이미지 분류 예시**

  입력 벡터는 각 픽셀의 RGB 값을 연결하여 구성되며, 또한 공간적 구조를 포함합니다. **예를 들어, 서로 위아래에 위치한 두 픽셀은 서로 밀접한 관계가 있습니다**.
- **분자의 동결점 및 비등점 예측 예시**

  분자는 다양한 수의 원자를 포함할 수 있고, 이는 여러 방식으로 연결될 수 있습니다. 이 경우, 모델은 분자의 기하학적 구조와 구성 원자를 함께 처리해야 합니다.


### 1.1.3 Machine learning models 
이 방정식은 입력을 출력으로 매핑하는 여러 곡선 중 하나로, 훈련 데이터를 사용해 선택됩니다.

훈련 데이터는 입력/출력 쌍으로 구성되며, 모델이 이 데이터를 가장 잘 설명하는 곡선을 찾습니다.

그림 1.2의 모델들도 훈련을 위해 레이블이 지정된 입출력 쌍이 필요합니다. 예를 들어, 음악 분류 모델은 각 오디오 클립의 장르를 사람이 식별한 다수의 오디오 클립이 필요합니다. 이러한 입출력 쌍은 훈련 과정에서 교사 또는 감독자의 역할을 하며, 이로 인해 ’지도 학습(supervised learning)’이라는 용어가 생겨났습니다.

즉 데이터를 입출력 데이터를 넣어주면 **지도 학습(supervised learning)** 이다. 

> 더 간단하게 내가 이해한 점을 보면 그냥 입출력 데이터는 사람이 넣어주야되고 그 데이터를 잘 표현하는 함수를 찾는 과정을 **지도학습** 이라고 이해하면 될 것 같다. 


> **trash in trash out** 이라는 얘기가 있는데 결국 이상한 데이터를 넣어주면 이상한 함수를 찾기 때문에 넣어주튼 데이터가 그만큼 중요해진다~~


### 1.1.4 Deep neural networks
이 책은 특히 유용한 기계 학습 모델인 심층 신경망(Deep Neural Networks)에 대해 다룹니다. 

심층 신경망은 입력과 출력 사이의 매우 광범위한 관계를 나타낼 수 있는 방정식으로, 훈련 데이터를 가장 잘 설명하는 관계를 쉽게 찾을 수 있습니다. 
- 단일 실수(회귀)
- 다수의 숫자(다변량 회귀)
- 여러 클래스에 대한 확률(이진 및 다중 클래스 분류)

을 출력할 수 있다. 

### 1.1.5 Structured outputs 
<img src="{{ site.url }}{{ site.baseurl }}/assets/img/understanding_dl/1-4.png" alt="">

1. **Figure 1.4a**: 다변량 이진 분류 모델이 입력 이미지의 각 픽셀을 소나 배경으로 분류하는 예시를 보여줍니다.
2. **Figure 1.4b**: 다변량 회귀 모델이 입력 이미지에서 각 픽셀의 깊이를 예측하는 예시를 보여줍니다.
3. 두 경우 모두 출력이 고차원적이며, 출력 구조가 입력 구조와 밀접하게 연관되어 있습니다.
4. **Figure 1.4c-e**: 출력 구조가 입력과 덜 연관된 복잡한 모델들을 보여줍니다.
5. **Figure 1.4c**: 입력이 오디오 파일이고, 출력이 해당 파일의 텍스트로 전사된 단어들입니다.
6. **Figure 1.4d**: 영어 텍스트를 프랑스어로 번역하는 모델입니다.
7. **Figure 1.4e**: 설명 텍스트를 기반으로 이미지를 생성하는 어려운 모델입니다.


## 1.2 Unsupervised learning 
출력 레이블이 없는 입력 데이터로부터 모델을 구축하는 것을 비지도 학습이라고 합니다. 출력 레이블이 없다는 것은 **“감독”** 이 없음을 의미합니다. 입력에서 출력으로의 매핑을 학습하는 대신, 데이터의 구조를 설명하거나 이해하는 것이 목표입니다. 지도 학습의 경우와 마찬가지로, 비지도 학습의 데이터도 매우 다양한 특성을 가질 수 있습니다. 데이터는 다음과 같을 수 있습니다:

- 이산적이거나 연속적일 수 있음
- 저차원 또는 고차원일 수 있음
- 일정한 길이 또는 가변적인 길이를 가질 수 있음

비지도 학습의 주요 초점은 레이블이 지정된 결과 없이 데이터 자체 내에서 패턴이나 구조를 발견하는 것입니다. 
> 이산적이다는 것은 연속적이지 않는 데이터를 얘기한다. (E.g: 슈팅횟수, 단속 횟수 등등)

### 1.2.1 Generative models (생성모델)
<img src="{{ site.url }}{{ site.baseurl }}/assets/img/understanding_dl/1-5.png" alt="">

<img src="{{ site.url }}{{ site.baseurl }}/assets/img/understanding_dl/1-8.png" alt="">

이 책은 **생성적 비지도 학습** 모델에 중점을 두고 있습니다. 
이러한 모델은 훈련 데이터와 **통계적으로 구별할 수 없는 새로운 데이터 예제** 를 합성하는 것을 학습합니다. 

### 1.2.2 Latent variables 

<img src="{{ site.url }}{{ site.baseurl }}/assets/img/understanding_dl/1-10.png" alt="">

일부(하지만 모든 것은 아님) 생성 모델들은 데이터가 관찰된 변수의 수보다 더 낮은 차원을 가질 수 있다.
> 그냥 어떠한 데이터가 있으면 더 적은 벡터(Latent Vector)로 표현할 수 있다는 내용인 것 같다.  

이로 인해 각 데이터 예제를 더 적은 수의 잠재 변수로 설명할 수 있다. 
여기서 딥러닝의 역할은 이러한 잠재 변수와 데이터 사이의 매핑을 설명하는 것입니다. 잠재 변수들은 일반적으로 설계에 의해 단순한 확률 분포를 가집니다. 이 분포에서 샘플링한 결과를 딥러닝 모델을 통해 전달함으로써 새로운 샘플을 생성할 수 있습니다(그림 1.10).
> 음 쉽게 생각하면 예를 들어 입대시 남성 평균키를 정규분포로 학습시킨다고 가정하면 평균과 표준편차만 찾으면 된다. 그래서 평균 175 표준편차 10이라는 것을 학습했으면 이를 기반으로 np.random.normal(175, 10, 1000)으로 1000명의 가짜 남성 키 데이터를 **생성하면** 이 데이터는 실제 남성 키 데이터랑 분포가 비슷할 것이당~~~


이러한 모델들은 실제 데이터를 조작하는 새로운 방법들을 제시합니다. 예를 들어, 두 개의 실제 예제를 뒷받침하는 잠재 변수를 찾는다고 가정해 보겠습니다. 우리는 이 예제들 사이의 잠재 표현을 보간(interpolation)하고, 중간 위치를 데이터 공간으로 다시 매핑함으로써 이 예제들 사이를 보간할 수 있습니다(그림 1.11).
> 그림 1.11에서 오른쪽 사진과 왼쪽 사진 2개만 있으면 오른쪽에서 왼쪽 사진으로 가는 그 가운데 사진들 보간할 수 있다는 내용이당




